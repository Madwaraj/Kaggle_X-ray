{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torch\nimport torchvision\nimport cv2\nimport pydicom\nimport random\nimport matplotlib.pyplot as plt\nimport math\nimport argparse\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_to_name(id):\n    id = int(id)\n    id = id-1\n    if id == 0:\n        return \"Aortic enlargement\"\n    if id == 1:\n        return \"Atelectasis\"\n    if id == 2:\n        return \"Calcification\"\n    if id == 3:\n        return \"Cardiomegaly\"\n    if id == 4:\n        return \"Consolidation\"\n    if id == 5:\n        return \"ILD\"\n    if id == 6:\n        return \"Infiltration\"\n    if id == 7:\n        return \"Lung Opacity\"\n    if id == 8:\n        return \"Nodule/Mass\"\n    if id == 9:\n        return \"Other lesion\"\n    if id == 10:\n        return \"Pleural effusion\"\n    if id == 11:\n        return \"Pleural thickening\"\n    if id == 12:\n        return \"Pneumothorax\"\n    if id == 13:\n        return \"Pulmonary fibrosis\"\n    else:\n        return str(id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nDIR_INPUT = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection'\nDIR_TRAIN = f'{DIR_INPUT}/train'\nDIR_TEST = f'{DIR_INPUT}/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(f'{DIR_INPUT}/train.csv')\ntrain_df.fillna(0, inplace=True)\ntrain_df.loc[train_df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n\nprint(f\"df Shape: {train_df.shape}\")\nprint(\"No Of Classes: \", train_df[\"class_id\"].nunique())\ntrain_df.sort_values(by='image_id').head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_ids = train_df['image_id'].sample(frac = 1).unique()\nvalidation_ids = image_ids[-3000:]# Tran and Validation Split \ntraining_ids = image_ids[:-3000]\n\n\nvalidation_df = train_df[train_df['image_id'].isin(validation_ids)]\ntraining_df= train_df[train_df['image_id'].isin(training_ids)]\n\n\ntraining_ids.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_box(image, boxes, IMG_SIZE):\n    boxes['x_min'] = ((boxes['x_min']/ np.shape(image)[0])* IMG_SIZE)\n    boxes['y_min'] = ((boxes['y_min']/ np.shape(image)[1])* IMG_SIZE)\n    \n    boxes['x_max'] = ((boxes['x_max']/ np.shape(image)[0])* IMG_SIZE)\n    boxes['y_max'] = ((boxes['y_max']/ np.shape(image)[1])* IMG_SIZE)\n    return boxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_pad(image):\n    row_size = np.shape(image)[0]\n    col_size = np.shape(image)[1]\n    image = np.pad(image, ((math.floor((4000-row_size)/2), math.ceil((4000-row_size)/2)), \n                           (math.floor((4000-col_size)/2), math.ceil((4000-col_size)/2))),\n                           'constant', constant_values=(0, 0))\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VinBigDataset(Dataset): #Class to load Training Data\n    \n    def __init__(self, dataframe, image_dir, transforms=None,stat = 'Train'):\n        super().__init__()\n        \n        self.image_ids = dataframe[\"image_id\"].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n        self.stat = stat\n        \n    def __getitem__(self, index):\n        IMG_SIZE = 512  \n        image_id = self.image_ids[index]\n        records = self.df[(self.df['image_id'] == image_id)]\n        records = records.reset_index(drop=True)\n\n        dicom = pydicom.dcmread(f\"{self.image_dir}/{image_id}.dicom\")\n\n        image = dicom.pixel_array\n      #  new_image = image\n        new_image = cv2.resize(image, (IMG_SIZE,IMG_SIZE))# norm the value dont div on 255 \n       # new_image = np.reshape(new_image, (IMG_SIZE, IMG_SIZE))\n        # new_image = np.asarray(new_image)\n        \"\"\"\n        image = image_pad(image)\n        #'MONOCHROME1' - White and black are inverted \n        if \"PhotometricInterpretation\" in dicom:\n            if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n                #Inverting Black and White\n                image = np.amax(image) - image\n        #dicom images are stored in certain way. In order to retrieve the image I, we tranform with image I= RescaleSlope* image+RescaleIntercept\n        intercept = dicom.RescaleIntercept if \"RescaleIntercept\" in dicom else 0.0\n        slope = dicom.RescaleSlope if \"RescaleSlope\" in dicom else 1.0\n\n        image = slope * image\n        image += intercept\n\n        #Rescaling the image\n        image = image - image.min()\n        image = image / image.max()\n        image = image * 255.0\n        #image = image.transpose(1,2,0)\n        \"\"\"\n        if records.loc[0, \"class_id\"] == 0:\n            records = records.loc[[0], :]\n\n        boxes = records[['x_min', 'y_min', 'x_max', 'y_max']]\n        boxes = define_box(image, boxes, IMG_SIZE).values\n        labels = torch.tensor(records[\"class_id\"].values, dtype=torch.int64)\n\n\n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([index])\n\n        if self.transforms:\n            sample = {\n                'image': new_image,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            sample = self.transforms(**sample)\n            new_image = torch.tensor(sample['image'])\n            \n            target['boxes'] = torch.tensor(sample['bboxes'])\n\n        if target[\"boxes\"].shape[0] == 0:\n            # Albumentation cuts the target (class 14, 1x1px in the corner)\n            target[\"boxes\"] = torch.from_numpy(np.array([[0.0, 0.0, 1.0, 1.0]]))\n            target[\"labels\"] = torch.tensor([0], dtype=torch.int64)\n\n        return new_image, target, image_ids\n    \n    def __len__(self):\n        return self.image_ids.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_dataset = VinBigDataset(training_df, DIR_TRAIN)\nvalid_dataset = VinBigDataset(validation_df, DIR_TRAIN)\n\n\n# split the dataset in train and test set\nindices = torch.randperm(len(train_dataset)).tolist()\n# Create train and validate data loader\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader = DataLoader(\n    valid_dataset,\n    batch_size=8,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train dataset sample\nimages, targets, image_ids = next(iter(train_data_loader))\nimages = list(image for image in images)\nimage_array = np.asarray(images)\n\ntargets = [{k: v for k, v in t.items()} for t in targets]\n\nfor number in random.sample([1,2,3,6,5,4],6):\n    boxes = targets[number]['boxes'].astype(np.int32)\n    img = images[number]\n    \n    labels= targets[number]['labels'].numpy().astype(np.int32)\n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\n    for i in range(len(boxes)):\n        img = cv2.rectangle(img,(boxes[i][0],boxes[i][1]),(boxes[i][2],boxes[i][3]),(255,0,0),2)\n        #print(le.inverse_transform([labels[i]-1])[0])\n        #print(label_to_name(labels[i]), (int(boxes[i][0]), int(boxes[i][1])))\n        img = cv2.putText(img, label_to_name(labels[i]), (int(boxes[i][0]), int(boxes[i][1])), cv2.FONT_HERSHEY_TRIPLEX,1, (255,0,0), 2, cv2.LINE_AA)\n\n    ax.set_axis_off()\n    ax.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNNEncoderSimple(nn.Module):\n    def __init__(self):\n        super(CNNEncoderSimple, self).__init__()\n        # input_dim  # b, 1, 1024, 1024\n        #layer 1\n        self.conv1 = nn.Conv2d(1, 8, 3, stride=1, padding=1)  # b, 8, 512,512\n        self.pool1 = nn.MaxPool2d(2, stride=2)  # b, 8, 256,256\n        self.conv1_bn = nn.BatchNorm2d(8)\n        #layer 2\n        self.conv2 = nn.Conv2d(8, 16, 3, stride=1, padding=1)  # b, 16, 256, 256\n        self.pool2 = nn.MaxPool2d(2, stride=2) #b, 16, 128, 128\n        self.conv2_bn = nn.BatchNorm2d(16)\n        #layer 3\n     #   self.conv3 = nn.Conv2d(16, 32, 3, stride=1, padding=1)  # b, 32, 256, 256\n     #   self.pool3 = nn.MaxPool2d(2, stride=2) #b, 32, 128, 128\n     #   self.conv3_bn = nn.BatchNorm2d(32)\n        \n        #layer 4\n        self.conv4 = nn.Conv2d(16, 8, 1, stride=1, padding=0)  #b, 32, 128, 128\n        self.conv4_bn = nn.BatchNorm2d(8)\n        #layer 5\n        self.conv5 = nn.Conv2d(8, 1, 1, stride=1, padding=0)  #b, 8, 128, 128\n        self.conv5_bn = nn.BatchNorm2d(1)\n        #layer 6\n        self.conv6 = nn.Conv2d(1, 1, 2, stride=2, padding=0)  #b, 1, 64, 64\n        \n        #self.fc1 = nn.Linear(32 * 12*12*12, 16 * 12*12*12)  # b, 55296 to 27648\n        #self.fc1_bn = nn.BatchNorm1d(16 * 12*12*12)\n        #self.fc2 = nn.Linear(16 * 12*12*12, 12*12*12)  # b, 27648 to 1728\n    \n    def forward(self, x):\n        #print(\"0 : x.\", x.size())\n   #     x = F.leaky_relu_(self.conv1(x))\n     #   print(\"1:\",x.size())\n    #    x = self.conv1_bn(self.pool1(x)) \n        print(\"2:\",x.size())\n        x = (F.leaky_relu_(self.conv2(x)))\n        x = self.conv2_bn(self.pool2(x)) \n        print(\"3:\",x.size())\n        x = (F.leaky_relu_(self.conv3(x)))\n        x = self.conv3_bn(self.pool3(x)) \n        x = (F.leaky_relu_(self.conv4(x)))\n        x = self.conv4_bn(x)\n        print(\"4:\",x.size())\n        x = (F.leaky_relu_(self.conv5(x)))\n        x = self.conv5_bn(x)\n        print(\"5:\",x.size())\n        x = self.conv6(x)\n        print(\"6:\",x.size())\n        x = x.reshape(x.shape[0], -1)\n        #print(\"4:\",x.size())\n        #x = self.fc1_bn(F.leaky_relu_(self.fc1(x)))\n        #print(\"5:\",x.size())\n        #x = self.fc2(x)\n        #print(\"6:\",x.size())\n        #exit()\n        return x    \n\n\n\nclass CNNDecoderSimple(nn.Module):\n    def __init__(self):\n        super(CNNDecoderSimple, self).__init__()\n        # Fully Connected Layers\n        self.fc1 = nn.Linear(64*64, 8*64*64)  # b, 4096 to 32,768\n        self.fc1_bn = nn.BatchNorm1d(8*64*64)\n\n        self.fc2 = nn.Linear(8*64*64,8 * 128*128)  # b, 32,768 to 131,072\n        self.fc2_bn = nn.BatchNorm1d(8*128*128)\n \n        self.fc3 = nn.Linear(8*128*128,32 * 128*128)  # b, 131,072 to \n        self.fc3_bn = nn.BatchNorm1d(16*128*128)\n\n      #  self.conv1 = nn.ConvTranspose2d(32, 16, 3, stride=1, padding=1)  # b, 16, 20,20,20\n       # self.conv1_bn = nn.BatchNorm2d(16)\n        \n        self.conv1 = nn.ConvTranspose2d(16, 8, 3, stride=1, padding=1)  # b, 16, 20,20,20\n        self.conv1_bn = nn.BatchNorm2d(8)\n        \n        self.conv2 = nn.ConvTranspose2d(8, 1, 3, stride=1, padding=1)  # b, 16, 40,40,40\n        \n\n        \n    \n    def forward(self, x):\n        x = self.fc1_bn(F.leaky_relu_(self.fc1(x)))\n        x = self.fc2_bn(F.leaky_relu_(self.fc2(x)))\n        x = self.fc3_bn(F.leaky_relu_(self.fc3(x)))\n        #print(\"After fc:\",x.size())\n        x = x.reshape(x.shape[0], 16,128, 128)\n        #print(\"Reshape :\",x.size())\n        x = self.conv1_bn(F.leaky_relu_(self.conv1(x)))\n     #   x = self.conv2_bn(F.leaky_relu_(self.conv2(x)))\n\n        #print(\"Conv1 :\", x.size())\n        x = nn.Tanh()(self.conv2(x))\n        #print(\"Conv2 :\", x.size())\n        #exit()\n        \n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_epoch(epoch, dataloader,encoder, decoder, optimizer, criterion, is_eval=False):\n    losses = []\n    if is_eval:\n        encoder.eval()\n    #    decoder.eval()\n    else:\n        encoder.train()\n    #    decoder.train()\n    for i,data in enumerate(dataloader):\n        if i % (10000 // 16) == 0:\n            print(f\"{i}/{len(dataloader)}\")\n        \n        image  = data[\"image\"]\n        #image = image*2 - 1\n        image = image.to(device=\"cuda:0\",dtype=torch.float)\n        \n        # ===================forward=====================\n        h = encoder(image)\n        #output = decoder(h)\n        #loss = criterion(output, image)\n        #losses.append(loss.detach())\n        # ===================backward====================\n        #if not is_eval:\n         #   optimizer.zero_grad()\n          #  loss.backward()\n           # optimizer.step()\n        \n    \n    #loss = torch.FloatTensor(losses).mean()\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pretrainer():\n    batch_size = 2\n    #dataset_train = load_data(f'{dataset_path}/training_images/', target_transform=transform)\n   # dataset_valid = load_data(f'{dataset_path}/validation_images/', target_transform=transform)\n    train_dataset = VinBigDataset(training_df, DIR_TRAIN)\n    dataloader_train = DataLoader(train_dataset, batch_size=batch_size, num_workers=4, collate_fn=collate_fn, shuffle=True)\n    #print(dataloader_train)\n    valid_dataset = VinBigDataset(validation_df, DIR_TRAIN)\n    dataloader_valid = DataLoader(valid_dataset, batch_size=batch_size, num_workers=4, collate_fn=collate_fn, shuffle=False)\n    #print(len(dataloader_train))\n    \n    encoder = CNNEncoderSimple()\n    decoder = CNNDecoderSimple()\n\n    epochs = 1\n    learning_rate = 1e-3\n    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)\n    criterion = nn.MSELoss(reduction='mean')\n    \n    for epoch in range(epochs):\n        epoch = epoch + 1\n        print(\"epoch = \", epoch)\n        if ((epoch+1)%10 == 0):\n            learning_rate = learning_rate/10.0\n            optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)\n     #   loss_train = run_epoch(epoch, dataloader_train, encoder, decoder, optimizer, criterion, is_eval=False)\n        loss_valid = run_epoch(epoch, dataloader_valid, encoder, decoder, optimizer, criterion, is_eval=True)\n        \n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrainer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}